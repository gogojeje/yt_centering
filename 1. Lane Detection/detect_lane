#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import rospy
import numpy as np
import cv2
import time
from cv_bridge import CvBridge
from sensor_msgs.msg import Image, CompressedImage
from std_msgs.msg import Float64
import psutil

class DetectLane():
    def __init__(self):
        # ROS 구독자와 발행자 설정
        self.sub_image_type = "raw"  # "compressed" or "raw"
        self.pub_image_type = "compressed"  # "compressed" or "raw"
        self.cvBridge = CvBridge()

        # 이미지 구독 설정
        if self.sub_image_type == "compressed":
            self.sub_image_original = rospy.Subscriber('/camera/image/compressed', CompressedImage, self.cbFindLane, queue_size=1)
        elif self.sub_image_type == "raw":
            self.sub_image_original = rospy.Subscriber('/camera/image', Image, self.cbFindLane, queue_size=1)

        # 이미지 발행 설정
        if self.pub_image_type == "compressed":
            self.pub_image_lane = rospy.Publisher('/detect/image_output/compressed', CompressedImage, queue_size=1)
        elif self.pub_image_type == "raw":
            self.pub_image_lane = rospy.Publisher('/detect/image_output', Image, queue_size=1)

        self.pub_lane = rospy.Publisher('/detect/lane', Float64, queue_size=1)  # Float64 타입으로 발행자 설정

        # 변수 초기화
        self.first_frame = True
        self.cache = np.zeros((8,))
        self.lane_center = (0, 0)  # lane_center 초기화

        # FPS를 계산하기 위한 변수 초기화
        self.frame_count = 0
        self.start_time = time.time()
        self.fps = 0  # FPS 변수 초기화

        # 클래스 인스턴스 변수 초기화
        self.r_x2, self.l_x1 = 0, 0
        self.pts = None
        
        
        # 로고 이미지 로드
        self.logo_image = cv2.imread('/home/gogojeje/catkin_ws/src/turtlebot3_autorace_2020/turtlebot3_autorace_detect/nodes/images/kosais.png')  # 로고 이미지 경로
        self.show_logo_time = 3  # 로고 표시 시간 (초)
        self.logo_display_start = None  # 로고 표시 시작 시간
        
        

    # 이미지 처리 관련 메서드들
    def grayscale(self, img):
        return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    def canny(self, img, low_threshold, high_threshold):
        return cv2.Canny(img, low_threshold, high_threshold)

    def gaussian_blur(self, img, kernel_size):
        return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)

    def region_of_interest(self, img, vertices):
        mask = np.zeros_like(img)
        if len(img.shape) > 2:
            channel_count = img.shape[2]
            ignore_mask_color = (255,) * channel_count
        else:
            ignore_mask_color = 255
        cv2.fillPoly(mask, vertices, ignore_mask_color)
        masked_image = cv2.bitwise_and(img, mask)
        return masked_image

    def get_slope(self, x1, y1, x2, y2):
        return (y2 - y1) / (x2 - x1)

    def draw_lines(self, img, lines):
        red = (0, 0, 255)  # 빨간색 정의
        y_global_min = img.shape[0]
        y_max = img.shape[0]

        l_slope, r_slope = [], []
        l_lane, r_lane = [], []

        det_slope = 0.5
        α = 0.2

        if lines is not None:
            for line in lines:
                for x1, y1, x2, y2 in line:
                    slope = self.get_slope(x1, y1, x2, y2)
                    if slope > det_slope:
                        r_slope.append(slope)
                        r_lane.append(line)
                    elif slope < -det_slope:
                        l_slope.append(slope)
                        l_lane.append(line)
                    y_global_min = min(y1, y2, y_global_min)

        if not l_lane or not r_lane:
            print('Error: No lanes detected')
            return

        l_slope_mean = np.mean(l_slope, axis=0)
        r_slope_mean = np.mean(r_slope, axis=0)
        l_mean = np.mean(np.array(l_lane), axis=0)
        r_mean = np.mean(np.array(r_lane), axis=0)

        if r_slope_mean == 0 or l_slope_mean == 0:
            print('Error: Dividing by zero')
            return

        l_b = l_mean[0][1] - (l_slope_mean * l_mean[0][0])
        r_b = r_mean[0][1] - (r_slope_mean * r_mean[0][0])

        if np.isnan((y_global_min - l_b) / l_slope_mean) or np.isnan((y_max - l_b) / l_slope_mean) or np.isnan((y_global_min - r_b) / r_slope_mean) or np.isnan((y_max - r_b) / r_slope_mean):
            print('Error: Calculation resulted in NaN')
            return

        l_x1 = int((y_global_min - l_b) / l_slope_mean)
        l_x2 = int((y_max - l_b) / l_slope_mean)
        r_x1 = int((y_global_min - r_b) / r_slope_mean)
        r_x2 = int((y_max - r_b) / r_slope_mean)

        # 클래스 인스턴스 변수에 계산 결과 저장
        self.r_x2, self.l_x1 = r_x2, l_x1

        # 이하 로직은 이전과 동일, 단 global 변수 대신 클래스 인스턴스 변수 사용

        if l_x1 > r_x1:  # Left line이 Right Line보다 오른쪽에 있는 경우 (Error)
            l_x1 = ((l_x1 + r_x1) / 2)
            r_x1 = l_x1

            l_y1 = ((l_slope_mean * l_x1) + l_b)
            r_y1 = ((r_slope_mean * r_x1) + r_b)
            l_y2 = ((l_slope_mean * l_x2) + l_b)
            r_y2 = ((r_slope_mean * r_x2) + r_b)

        else:  # l_x1 < r_x1 (Normal)
            l_y1 = y_global_min
            l_y2 = y_max
            r_y1 = y_global_min
            r_y2 = y_max

        current_frame = np.array([l_x1, l_y1, l_x2, l_y2, r_x1, r_y1, r_x2, r_y2], dtype="float32")

        if self.first_frame == 1:
            self.next_frame = current_frame
            self.first_frame = 0
        else:
            prev_frame = self.cache
            self.next_frame = (1 - α) * prev_frame + α * current_frame

        self.pts = np.array([[self.next_frame[0], self.next_frame[1]], [self.next_frame[2], self.next_frame[3]], [self.next_frame[6], self.next_frame[7]], [self.next_frame[4], self.next_frame[5]]], np.int32)
        self.pts = self.pts.reshape((-1, 1, 2))

        div = 2
        self.l_center = (int((self.next_frame[0] + self.next_frame[2]) / div), int((self.next_frame[1] + self.next_frame[3]) / div))
        self.r_center = (int((self.next_frame[4] + self.next_frame[6]) / div), int((self.next_frame[5] + self.next_frame[7]) / div))
        self.lane_center = (int((self.l_center[0] + self.r_center[0]) / div), int((self.l_center[1] + self.r_center[1]) / div))

        self.uxhalf = int((self.next_frame[2] + self.next_frame[6]) / 2)
        self.uyhalf = int((self.next_frame[3] + self.next_frame[7]) / 2)
        self.dxhalf = int((self.next_frame[0] + self.next_frame[4]) / 2)
        self.dyhalf = int((self.next_frame[1] + self.next_frame[5]) / 2)

        cv2.line(img, (int(self.next_frame[0]), int(self.next_frame[1])), (int(self.next_frame[2]), int(self.next_frame[3])), red, 2)
        cv2.line(img, (int(self.next_frame[4]), int(self.next_frame[5])), (int(self.next_frame[6]), int(self.next_frame[7])), red, 2)
        self.cache = self.next_frame

        return 0, l_x1, l_x2, r_x1, r_x2

    def hough_lines(self, img, rho, theta, threshold, min_line_len, max_line_gap):
        lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)
        line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)
        self.draw_lines(line_img, lines)  # 'self'를 추가했습니다.
        return line_img

    def weighted_img(self, img, initial_img, α=0.8, β=1., λ=0.):
        initial_img_resized = cv2.resize(initial_img, (img.shape[1], img.shape[0]))  # initial_img의 크기를 img와 동일하게 조정
        return cv2.addWeighted(initial_img_resized, α, img, β, λ)

    def get_pts(self, flag=0):
        # 새로운 이미지 크기에 맞게 꼭짓점 좌표 조정
        vertices1 = np.array([
            [0, 430],
            [225, 250],
            [405, 250],
            [630, 430]
        ])

        vertices2 = np.array([
            [0, 480],
            [275, 110],
            [365, 110],
            [640, 480]
        ])
        if flag == 0:
            return vertices1
        if flag == 1:
            return vertices2

    def process_image(self, image):
        # 입력 이미지가 비어 있는 경우 체크
        if image is None:
            print("Error: Input image is empty.")
            return None, None

        # 이미지 사이즈 조정
        resized_image = cv2.resize(image, (640, 480))

        # 필요한 변수들 설정
        kernel_size = 3
        low_thresh = 100
        high_thresh = 150
        rho = 4
        theta = np.pi / 180
        thresh = 100
        min_line_len = 50
        max_line_gap = 150

        # gray_image 처리를 self.grayscale 메서드로 변경
        gray_image = self.grayscale(resized_image)

        # HSV 변환
        img_hsv = cv2.cvtColor(resized_image, cv2.COLOR_RGB2HSV)

        # 노란색과 흰색 마스크 설정
        lower_yellow = np.array([20, 100, 100], dtype="uint8")
        upper_yellow = np.array([30, 255, 255], dtype="uint8")
        mask_yellow = cv2.inRange(img_hsv, lower_yellow, upper_yellow)
        mask_white = cv2.inRange(gray_image, 100, 255)

        # 마스크 결합
        mask_yw = cv2.bitwise_or(mask_white, mask_yellow)
        mask_yw_image = cv2.bitwise_and(gray_image, mask_yw)

        # 가우시안 블러 처리
        gauss_gray = self.gaussian_blur(mask_yw_image, kernel_size)

        # Canny Edge Detection
        canny_edges = self.canny(gauss_gray, low_thresh, high_thresh)

        # 관심 영역 설정
        vertices = [self.get_pts(flag=0)]
        roi_image = self.region_of_interest(canny_edges, vertices)

        # Hough 변환을 이용한 선 검출
        line_image = self.hough_lines(roi_image, rho, theta, thresh, min_line_len, max_line_gap)

        # line_image의 크기를 조정합니다.
        resized_line_image = cv2.resize(line_image, (640, 480))


        # cv2.addWeighted 함수를 사용하기 전에 두 이미지의 크기를 일치시킵니다.
        result = self.weighted_img(resized_line_image, image, α=0.8, β=1., λ=0.)
        
        # mask = cv2.polylines(result, vertices, True, (0, 255, 255))  # ROI mask


        return result, resized_image


    def draw_text_with_border(self, img, text, position, font, font_scale, text_color, border_color, thickness):
        # 텍스트의 테두리 그리기
        for x_offset, y_offset in [(1, 1), (-1, -1), (1, -1), (-1, 1)]:
            cv2.putText(img, text, (position[0] + x_offset, position[1] + y_offset), font, font_scale, border_color, 3)

        # 원래 텍스트 그리기
        cv2.putText(img, text, position, font, font_scale, text_color, 2)


    def get_cpu_usage(self):
        cpu_usage = psutil.cpu_percent(interval=None)

        return cpu_usage



    def visualize(self, result):
        height, width = result.shape[:2]
        length = 30
        thickness = 3
        whalf = int(width / 2)

        # 색상 정의 (BGR 형식)
        yellow = (0, 255, 255)
        white = (255, 255, 255)
        red = (0, 0, 255)
        green = (0, 255, 0)
        orange = (0, 165, 255)  # 주황색 BGR 값

        lane_width_pixels = self.l_center[0] - self.r_center[0]  # 클래스 멤버 변수 사용
		




        # Warning Boundary
        gap = 14
        length2 = 10
        cv2.line(result, (whalf - gap, self.lane_center[1] - length2), (whalf - gap, self.lane_center[1] + length2), white, 1)
        cv2.line(result, (whalf + gap, self.lane_center[1] - length2), (whalf + gap, self.lane_center[1] + length2), white, 1)

        # Lane Position
        cv2.line(result, (self.l_center[0], self.l_center[1]), (self.l_center[0], self.l_center[1] - length), red, thickness)
        cv2.line(result, (self.r_center[0], self.r_center[1]), (self.r_center[0], self.r_center[1] - length), red, thickness)

        # 중앙 오프셋 및 차선 곡률에 대한 정보 표시
        font = cv2.FONT_HERSHEY_SIMPLEX
        lane_width_meters = 0.20
        xm_per_pix = lane_width_meters / lane_width_pixels

        hei = 30
        font_size = 2

        # WARNING 및 방향 텍스트 추가
        warning_color = (0, 0, 0)  # 초기화
        offset_cm = 0  # offset_cm 초기화

        if self.lane_center[0] == whalf:
            text = 'PERFECT : 100%'
            warning_color = green  # 중앙으로부터 1센치 미만일 때 초록색
        else:
            offset = (self.lane_center[0] - whalf) * xm_per_pix
            direction = 'Left' if self.lane_center[0] < whalf else 'Right'
            offset_cm = abs(offset) *100 # 거리를 센티미터로 표시
            if offset_cm < 0.5:
                text = f'STABLE : Turn {direction} {offset_cm:.2f}cm'
                warning_color = green  # 중앙으로부터 1센치 미만일 때 초록색
            elif offset_cm < 1.5:
                text = f'WARNING : Turn {direction} {offset_cm:.2f}cm'
                warning_color = orange  # 중앙으로부터 2센치 미만일 때 주황색
            else:
                text = f'WARNING : Turn {direction} {offset_cm:.2f}cm'
                warning_color = red  # 중앙으로부터 3센치 이상일 때 빨간색

       

        # 선 색상 결정
        if offset_cm < 0.5:
            line_color = green
        elif offset_cm < 1.5:
            line_color = orange
        else:
            line_color = red

        # 선 그리기
        cv2.line(result, (whalf, self.lane_center[1]), (whalf, height), line_color, 2)
        cv2.line(result, (whalf, self.lane_center[1]), (self.lane_center[0], self.lane_center[1]), line_color, 2)


        # 텍스트 크기 얻기
        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]

        # 화면 가로 중앙에 텍스트를 가운데 맞추기 위한 위치 계산
        text_x = 150

        # 화면 상단에 표시하려면 상단 여백을 30으로 설정하거나 원하는 위치로 조절 가능
        text_y = 30

        # 텍스트 표시
        self.draw_text_with_border(result, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, warning_color, (0, 0, 0), 2)


        
        # 글씨체 변경
        font = cv2.FONT_HERSHEY_SIMPLEX  # 이 부분을 변경하여 다른 글씨체를 사용

        info_position_y = 15
        line_spacing = 20  # 각 정보 사이의 라인 간격

        # 왼쪽 상단에 FPS, CPU 사용률 표시
        cpu_usage = self.get_cpu_usage()


        # CPU 사용률 표시
        self.draw_text_with_border(result, f'CPU: {round(cpu_usage)}%', (5, info_position_y + line_spacing), font, 0.55, (0, 255, 0), (0, 0, 0), 1)


        # FPS 표시
        self.draw_text_with_border(result, f'FPS: {round(self.fps)}', (5, info_position_y), font, 0.55, (0, 255, 0), (0, 0, 0), 1)


        return result




    def Region(self, image):
        height, width = image.shape[:2]
        zeros = np.zeros_like(image)

        # 색상 정의 (BGR 형식)
        lime = (0, 255, 0)

        if self.pts is not None:
            mask = cv2.fillPoly(zeros, [self.pts], lime)
            result = cv2.addWeighted(image, 1, mask, 0.3, 0)

            if self.lane_center[1] >= height / 2:
                result = self.visualize(result)
        else:
            result = image

        return result






    def Lane_Detection(self, frame):
        processing, _ = self.process_image(frame)
        region = self.Region(processing)
        
        # FPS 계산
        self.frame_count += 1
        elapsed_time = time.time() - self.start_time
        if elapsed_time >= 1.0:  # 1초마다 FPS 업데이트
            self.fps = self.frame_count / elapsed_time  # FPS 값을 self.fps에 저장
            self.start_time = time.time()
            self.frame_count = 0
        
        # 차선의 중앙 지점을 계산
        # 예: self.lane_center[0]는 x 좌표
        lane_center_msg = Float64()
        lane_center_msg.data = self.lane_center[0]
        self.pub_lane.publish(lane_center_msg)

        return region, lane_center_msg  # region과 lane_center_msg를 반환
        
        


    def cbFindLane(self, image_msg):
        try:
            if self.logo_display_start is None:
                self.logo_display_start = time.time()

            time_since_logo_start = time.time() - self.logo_display_start

            if time_since_logo_start < self.show_logo_time:
                # 로고 표시 로직
                try:
                    if self.pub_image_type == "compressed":
                        compressed_logo_msg = self.cvBridge.cv2_to_compressed_imgmsg(self.logo_image, "jpg")
                        self.pub_image_lane.publish(compressed_logo_msg)
                    elif self.pub_image_type == "raw":
                        logo_msg = self.cvBridge.cv2_to_imgmsg(self.logo_image, "bgr8")
                        self.pub_image_lane.publish(logo_msg)
                except CvBridgeError as e:
                    rospy.logerr("CvBridge 오류: %s" % e)
                return

            # 로고 표시 시간이 지난 후 차선 감지 로직
            # cv_image 정의
            if self.sub_image_type == "compressed":
                np_arr = np.frombuffer(image_msg.data, np.uint8)
                cv_image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            elif self.sub_image_type == "raw":
                cv_image = self.cvBridge.imgmsg_to_cv2(image_msg, "bgr8")

            processed_image, lane_center_msg = self.Lane_Detection(cv_image)

            # 이미지 메시지를 생성하고 데이터를 설정
            lane_msg = Image()
            lane_msg.header = image_msg.header
            lane_msg.height, lane_msg.width, lane_msg.encoding = processed_image.shape[0], processed_image.shape[1], "bgr8"
            lane_msg.step = lane_msg.width * 3
            lane_msg.data = processed_image.tobytes()

            # 이미지 발행
            if self.pub_image_type == "compressed":
                self.pub_image_lane.publish(self.cvBridge.cv2_to_compressed_imgmsg(processed_image, "jpg"))
            elif self.pub_image_type == "raw":
                self.pub_image_lane.publish(self.cvBridge.cv2_to_imgmsg(processed_image, "bgr8"))

            # 차선의 중앙 지점 발행
            self.pub_lane.publish(lane_center_msg)

        except AttributeError:
            # AttributeError 발생 시 무시
            pass





    def main(self):
        self.start_time = time.time()  # 노드 시작 시간 설정
        rospy.spin()

if __name__ == '__main__':
    rospy.init_node('detect_lane')
    node = DetectLane()
    node.main()

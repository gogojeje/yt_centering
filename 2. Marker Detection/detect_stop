#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import rospy
import cv2
import numpy as np
import time
import math
import psutil
from ultralytics import YOLO
from cv_bridge import CvBridge, CvBridgeError
from std_msgs.msg import Float64, String
from sensor_msgs.msg import Image, CompressedImage

class WebcamDetector:
    def __init__(self):
        rospy.init_node('webcam_detector', anonymous=True)

        self.image_pub = rospy.Publisher('/detection_image', Image, queue_size=10)
        self.detection_pub = rospy.Publisher('/detection_results', String, queue_size=10)
        self.pub_stop_signal = rospy.Publisher('/detect/stop_signal', Float64, queue_size=10)

        self.logo_image = cv2.imread('/home/gogojeje/catkin_ws/src/turtlebot3_autorace_2020/turtlebot3_autorace_detect/nodes/images/kosais.png')
        self.show_logo_time = 3
        self.logo_display_start = rospy.get_time()
        self.sorted_box = []  # 컨투어를 저장할 변수

        # 로고 이미지 로드
        self.logo_image = cv2.imread('/home/gogojeje/catkin_ws/src/turtlebot3_autorace_2020/turtlebot3_autorace_detect/nodes/images/kosais.png')
        self.show_logo_time = 3
        self.logo_display_start = rospy.get_time()


        try:
            self.model = YOLO('/home/gogojeje/catkin_ws/src/turtlebot3_autorace_2020/turtlebot3_autorace_detect/nodes/best-bod.pt')
            rospy.loginfo("YOLO model successfully loaded.")
        except Exception as e:
            rospy.logerr(f"Failed to load YOLO model: {e}")

        self.bridge = CvBridge()

        self.cap = cv2.VideoCapture(0)
        self.cap.set(3, 640)
        self.cap.set(4, 480)

        self.prev_time = 0
        self.out_bb = 12
        self.in_bb = 13

    def inoutside_determine(self, coordinates, standard_polygon):
        result_count = 0

        a,b,c,d = standard_polygon
        standart_polygon=[[a,b],[a,d],[c,d],[c,b]]


        for point in coordinates:
            n = len(standart_polygon)
            x, y = point
            result = False

            p1x, p1y = standart_polygon[0]
            print(p1x,p1y)
            for i in range(n + 1):
                p2x, p2y = standart_polygon[i % n]
                if y > min(p1y, p2y) and y <= max(p1y, p2y) and x <= max(p1x, p2x):
                    if p1y != p2y:
                        xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                        if p1x == p2x or x <= xinters:
                            result = not result
                p1x, p1y = p2x, p2y

            if result==True:
                print("점은 다각형 내부에 있습니다.")
                result_count += 1
                print(result_count)

            else:
                print("점은 다각형 외부에 있습니다.")
                result_count += 2
                print(result_count)

        return result_count

    def get_bboxes_xyxy(self, image):
        # 모델이 이미 초기화된 것으로 가정
        results = self.model(image)

        xyxy = []
        xywh = []

        if results:
            for result in results:
                if len(result.boxes) > 0:
                    xyxy = result.boxes.xyxy.cpu().numpy()
                    xywh = result.boxes.xywh.cpu().numpy()
                else:
                    xyxy = np.array([[0, 0, 0, 0]])
                    xywh = np.array([[0, 0, 0, 0]])
        else:
            xyxy = np.array([[0, 0, 0, 0]])
            xywh = np.array([[0, 0, 0, 0]])
        return xyxy, xywh

    def webcam_FPS_output(self, frame):
        cur_time = time.time()

        sec = cur_time - self.prev_time
        self.prev_time = cur_time

        fps = 1 / (sec)

        # 프레임 수를 문자열에 저장
        fps_str = "FPS: %0.1f" % fps
        
        # 변경사항 적용: 글씨체, 크기, 굵기, 테두리
        font = cv2.FONT_HERSHEY_SIMPLEX  # 변경된 글씨체
        font_scale = 0.7  # 변경된 글씨 크기
        thickness = 2  # 변경된 굵기

        # 테두리 그리기
        text_color_border = (0, 0, 0)  # 테두리 색상: 검정
        cv2.putText(frame, fps_str, (10, 20), font, font_scale, text_color_border, thickness + 3)

        # 원본 텍스트 그리기
        text_color = (0, 255, 0)  # 텍스트 색상: 초록
        cv2.putText(frame, fps_str, (10, 20), font, font_scale, text_color, thickness)

    def get_cpu_usage(self, frame):
        # CPU 점유율
        cpu_usage = psutil.cpu_percent(interval=None)

        cpu_text = f'CPU: {cpu_usage:.2f}%'

        # 변경사항 적용: 글씨체, 크기, 굵기, 테두리
        font = cv2.FONT_HERSHEY_SIMPLEX  # 변경된 글씨체
        font_scale = 0.7  # 변경된 글씨 크기
        thickness = 2  # 변경된 굵기

        # 테두리 그리기
        text_color_border = (0, 0, 0)  # 테두리 색상: 검정
        cv2.putText(frame, cpu_text, (10, 50), font, font_scale, text_color_border, thickness + 3)

        # 원본 텍스트 그리기
        text_color = (0, 255, 0)  # 텍스트 색상: 초록
        cv2.putText(frame, cpu_text, (10, 50), font, font_scale, text_color, thickness)


    def calculate_angle(self, a, b, c):
        # 벡터 AB
        vector_ab = [a[0] - b[0], a[1] - b[1]]

        # 벡터 BC
        vector_bc = [c[0] - b[0], c[1] - b[1]]

        # 내적 계산
        dot_product = vector_ab[0] * vector_bc[0] + vector_ab[1] * vector_bc[1]

        # 벡터 크기 계산
        magnitude_ab = math.sqrt(vector_ab[0] ** 2 + vector_ab[1] ** 2)
        magnitude_bc = math.sqrt(vector_bc[0] ** 2 + vector_bc[1] ** 2)

        # 코사인 값 계산
        cosine_value = dot_product / (magnitude_ab * magnitude_bc)

        # 각도 계산
        angle_radian = math.acos(cosine_value)

        # 라디안을 도로 변환
        angle_degree = math.degrees(angle_radian)

        return int(angle_degree)

    def process_frame(self):
        ret, frame = self.cap.read()
        if not ret:
            rospy.logerr("카메라에서 이미지를 읽을 수 없습니다.")
            return

        # 현재 시간과 로고 표시 시작 시간의 차이 계산
        time_since_logo_start = rospy.get_time() - self.logo_display_start

        # 로고 표시 시간이 3초 미만인 경우
        if time_since_logo_start < self.show_logo_time:
            # 로고 이미지를 ROS 메시지로 변환하여 게시
            try:
                ros_image = self.bridge.cv2_to_imgmsg(self.logo_image, "bgr8")
                self.image_pub.publish(ros_image)
            except CvBridgeError as e:
                rospy.logerr(e)
            return
        
        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
        height, width = frame.shape[:2]
        screen_center_y = height // 2  # 화면 중앙 y 좌표

        # frame center
        whalf = width // 2
        hhalf = height // 2

        # 픽셀-센티미터 변환 비율
        pixel_to_cm_ratio = 35  # 10 픽셀이 1cm

        # object_detector 함수로 검출 결과 얻기
        xyxy, xywh = self.get_bboxes_xyxy(frame)
        for bbox in xyxy:
            x1, y1, x2, y2 = bbox
            center_x, center_y = int((x1 + x2) / 2), int((y1 + y2) / 2)


            # 중앙과의 거리 계산 및 표시 (센티미터 단위)
            distance_y = (center_y - screen_center_y) / pixel_to_cm_ratio
            distance_text = f"Vertical Gap: {distance_y:.2f}cm"
            
            # 글씨 테두리 (검은색)
            font_scale = 0.7
            thickness = 2
            font = cv2.FONT_HERSHEY_SIMPLEX
            text_size = cv2.getTextSize(distance_text, font, font_scale, thickness)[0]
            text_x = center_x + 10
            text_y = center_y - text_size[1] - 10  # 텍스트를 검은 점 위쪽으로 이동

            cv2.putText(frame, distance_text, (text_x, text_y), font, font_scale, (0, 0, 0), thickness + 3)

            # 글씨 (흰색)
            cv2.putText(frame, distance_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness)

        
        # 여기에 정지 신호 발행 로직 추가
        real_h = 11.2
        stop_threshold = 5
        h_per_pixel = real_h / (y2 - y1)
        distance_y = (center_y - screen_center_y) / pixel_to_cm_ratio

        # 정지 신호 발행 조건 변경: distance_y가 +-2cm 이내일 때
        stop_signal = Float64()
        if abs(distance_y) <= 1.0:  # distance_y가 +-2cm 이내일 때
            stop_signal.data = 1.0
        else:
            stop_signal.data = 0.0
        self.pub_stop_signal.publish(stop_signal)



        for item in xyxy:
            masked_f = frame.copy()
            out_bbox = [float(x1 - self.out_bb), float(y1 - self.out_bb), float(x2 + self.out_bb), float(y2 + self.out_bb)]
            in_bbox = [float(x1 + self.in_bb), float(y1 + self.in_bb), float(x2 - self.in_bb), float(y2 - self.in_bb)]

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 100)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for contour in contours:
                if cv2.contourArea(contour) > 300:
                    rect = cv2.minAreaRect(contour)
                    box = cv2.boxPoints(rect)
                    box = np.int0(box)

                    if (
                        self.inoutside_determine(box, in_bbox) == 8
                        and
                        self.inoutside_determine(box, out_bbox) == 4
                    ):
                        for point in box:
                            cv2.circle(frame, tuple(point), 5, (0, 255, 0), -1)

                        sorted_box = sorted(box, key=lambda point: point[1], reverse=True)
                        C_xhalf = int((sorted_box[0][0] + sorted_box[3][0]) / 2)
                        C_yhalf = int((sorted_box[0][1] + sorted_box[3][1]) / 2)
                        cv2.circle(frame, (int((sorted_box[0][0] + sorted_box[3][0]) / 2), int((sorted_box[0][1] + sorted_box[3][1]) / 2)), 5, (0, 0, 0), -1)

                        dx = whalf - C_xhalf
                        dy = hhalf - C_yhalf - 233
                        sorted_box_moved = [[point[0] + dx, point[1] + dy] for point in sorted_box]
                        angle_moved_h = [int((sorted_box_moved[2][0] + sorted_box_moved[3][0]) / 2),
                                         int((sorted_box_moved[2][1] + sorted_box_moved[3][1]) / 2)]
                        moved_C_center = [C_xhalf + dx, C_yhalf + dy]

                        angle = self.calculate_angle([whalf, 0], moved_C_center, angle_moved_h)
                        if angle >= 45 or angle == 0:
                            cv2.putText(frame, f"Stable", (whalf-50, C_yhalf+dy+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
                        else:
                            cv2.putText(frame, f"{angle} deg", (whalf-50, C_yhalf+dy+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)
                            cv2.line(frame, angle_moved_h, moved_C_center, (255, 0, 0), 2)

                        cv2.drawContours(frame, [box], 0, (0, 255, 0), 2)
                    else:
                        continue

        if x1 and y1 and x2 and y2:
            cv2.rectangle(frame, (int(x1 - self.out_bb), int(y1 - self.out_bb)), (int(x2 + self.out_bb), int(y2 + self.out_bb)), (0, 0, 255), 2)
            cv2.rectangle(frame, (int(x1 + self.in_bb), int(y1 + self.in_bb)), (int(x2 - self.in_bb), int(y2 - self.in_bb)), (0, 0, 255), 2)
            if abs(distance_y) <= 0.5:  # distance_y가 +-0.5cm 이내일 때
                cv2.putText(frame, "Centered", (whalf - 50, hhalf), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        else:
            print("인식되는 오브젝트가 없습니다.")

        cv2.line(frame, [whalf, 0], [whalf, 90], (255, 0, 0), 2)
        cv2.circle(frame, (whalf, hhalf), 5, (0, 0, 255), -1)

        self.webcam_FPS_output(frame)
        self.get_cpu_usage(frame)


        # ROS 메시지로 변환하여 발행합니다.
        try:
            ros_image = self.bridge.cv2_to_imgmsg(frame, "bgr8")
            self.image_pub.publish(ros_image)
        except CvBridgeError as e:
            rospy.logerr(e)

    def main(self):
        while not rospy.is_shutdown():
            self.process_frame()

if __name__ == '__main__':
    node = WebcamDetector()
    node.main()


